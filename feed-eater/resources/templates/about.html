{% extends "templates/base.html" %}
{% block content %}
<h1>About Fetish Storm and Feed Eater</h1>
  <p>
     Here's a Diagram to show the Components of the System.
     This diagram doesn't illustrate every connection, but really, this is an
     initial prototype.  Currently, Datomic data storage is not yet implemented.
     Also, to really make this work, we need a complete authentication and
     authorization framework.
  </p>
  <p>
     In Production, there would slightly more complexity to account for horizontal
     scaling.  Each component has its strengths and weaknesses.
  </p>
<br />
<img src="/img/FetishStormDeployment.png" />
<br />
<h2>Storm</h2>
  <p>
     Storm was chosen for its fault-tolerant real-time map reduce.  Also, a Storm cluster
     is built on ZooKeeper, and is distributed.  Nimbus controls and orchestrates the whole thing,
     and Nimbus is almost a single point of failure.  I say almost because if Nimbus fails, workers
     will continue to run, but won't fail over to other hosts in the cluster if needed.  This means
     that monitoring Nimbus should be a bit of a "high touch" situation in the sense that an
     untreated Niumbus failure can eventually result in cascading Storm failure.
  </p>
  <p>
     How?  If Nimbus can't move workers to different hosts, and the JVM is leaking memory, everything
     is going to grind to a halt.  Since these computations are real time, this failure could result in
     either a back log or just missing data.
  </p>
  <p>
     A quick search for Storm users indicates many Engineers are adding Hadoop for batch processing.
     The purpose for adding Datomic is that we can record unique state of our data while preserving its
     immutability.  (Datomic is not yet implemented in this prototype.)
  </p>
<h2>Write API</h2>
  <p>
     This system is designed to have data pushed to its Datomic via the (unimplemented) Write API which
     aggregates data from the customers.
     This API should be transactional.
  </p>
<h2>Read API</h2>
  <p>
     The Read API is called by the web tier to pull data from Redis.  Early versions of this API should
     probably sort, marshal, filter, etc. the data before it is presented to the web tier.  However, other
     Engineers are likely to make valid cases for off-loading a large bulk of this data manipulation to the
     client.
  </p>
  <p>
     The best solution is probably somewhere in the middle since pushing a lot of the data manipulation to
     the DOM makes assumptions about the customer that may not be true.  However, broadband is fairly
     ubiquitous, but that does not necessarily mean mobile devices will have the resources to handle large
     JavaScript calculations on JSON objects.
  </p>


{% endblock %}
